{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 150\n",
    "\n",
    "data = {\n",
    "    'sepal_length': np.random.uniform(4.0, 8.0, n_samples),\n",
    "    'sepal_width': np.random.uniform(2.0, 4.5, n_samples),\n",
    "    'petal_length': np.random.uniform(1.0, 7.0, n_samples),\n",
    "    'petal_width': np.random.uniform(0.1, 2.5, n_samples),\n",
    "    'species': np.random.choice(['setosa', 'versicolor', 'virginica'], n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'C:\\Users\\DELL\\Downloads\\Iris.csv'  # Adjust the file name\n",
    "df_from_csv = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width     species\n",
      "0      5.498160     4.270665      1.310090     1.965153      setosa\n",
      "1      7.802857     2.598905      4.188128     1.440170  versicolor\n",
      "2      6.927976     2.362237      4.243811     1.118133  versicolor\n",
      "3      6.394634     3.223632      4.824579     2.275251      setosa\n",
      "4      4.624075     4.464126      5.356548     0.366874  versicolor\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows and check for missing values\n",
    "print(df.head())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "df['species'] = le.fit_transform(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernels to test\n",
    "kernels = ['linear', 'poly', 'rbf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    # Create and train the SVM classifier\n",
    "    svm = SVC(kernel=kernel, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[kernel] = {\n",
    "        'accuracy': accuracy,\n",
    "        'report': classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for linear kernel:\n",
      "Accuracy: 0.2000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       0.00      0.00      0.00         9\n",
      "  versicolor       0.28      0.42      0.33        12\n",
      "   virginica       0.11      0.11      0.11         9\n",
      "\n",
      "    accuracy                           0.20        30\n",
      "   macro avg       0.13      0.18      0.15        30\n",
      "weighted avg       0.14      0.20      0.17        30\n",
      "\n",
      "\n",
      "Results for poly kernel:\n",
      "Accuracy: 0.3333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       0.00      0.00      0.00         9\n",
      "  versicolor       0.40      0.83      0.54        12\n",
      "   virginica       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.33        30\n",
      "   macro avg       0.13      0.28      0.18        30\n",
      "weighted avg       0.16      0.33      0.22        30\n",
      "\n",
      "\n",
      "Results for rbf kernel:\n",
      "Accuracy: 0.3000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       0.50      0.11      0.18         9\n",
      "  versicolor       0.33      0.50      0.40        12\n",
      "   virginica       0.20      0.22      0.21         9\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.34      0.28      0.26        30\n",
      "weighted avg       0.34      0.30      0.28        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for kernel, result in results.items():\n",
    "    print(f\"\\nResults for {kernel} kernel:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(result['report'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
